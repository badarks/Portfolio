{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 : Boolean Decision Tree\n",
    "* CS 5300 : Artificial Intelligent\n",
    "* Kyu Cho\n",
    "* 4/13/16\n",
    "\n",
    "## Data Description\n",
    "### Intro\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "### Variables\n",
    "Note: This data already has been preprocessed.\n",
    "\n",
    "\n",
    "**Sex** : Sex (1 = Female; 0 = Male)  \n",
    "**FamilySize** : Family (1 = Aboard with Family; 0 = Aboard without Family)  \n",
    "**Child** : Child (age < 16) (1 = Child; 0 = Not Child)  \n",
    "**Pclass.2** : Passenger class (1 = 2nd Class; 0 = 1st or 3rd Class)  \n",
    "**Pclass.3** : Passenger class (1 = 3rd Class; 0 = 1st or 2nd Class)  \n",
    "Note : It does not have value for 1st class because if Pclass.2 = 0 and Pclass.3 = 0 meaning it's Pclass.1.  \n",
    "**Survive** : Survival (0 = No; 1 = Yes)  \n",
    "\n",
    "## Implementation\n",
    "Here is the outline of this program.\n",
    "1. Build a binary decision tree from scratch.\n",
    "2. Make predictions using the decision tree.\n",
    "3. Evaluate the accuracy of the decision tree.\n",
    "\n",
    "I've implemented following conditions to stop building tree or prunning the tree.\n",
    "1. **Stopping condition 1:** All data points in a node are from the same class.\n",
    "2. **Stopping condition 2:** No more features to split on.\n",
    "3. **Early Stopping condition 1:** Reached maximum depth threshold.\n",
    "4. **Early Stopping condition 2:** Reached minimum node size threshold.\n",
    "5. **Early Stopping condition 3:** Reached minimum entropy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "os.chdir('C:\\Users\\Kyu\\Documents\\python\\data')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  FamilySize  Child  Pclass.2  Pclass.3  Survived\n",
      "0    0           0      0         0         1         0\n",
      "1    1           0      0         0         0         1\n",
      "2    1           0      0         0         0         1\n",
      "3    0           0      0         0         1         0\n",
      "4    0           0      0         0         0         0\n",
      "5    0           1      1         0         1         0\n",
      "6    1           1      0         0         1         1\n",
      "7    1           0      1         1         0         1\n",
      "8    1           1      1         0         1         1\n",
      "9    1           0      0         0         0         1\n"
     ]
    }
   ],
   "source": [
    "print(train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  FamilySize  Child  Pclass.2  Pclass.3  Survived\n",
      "0    1           0      0         0         1         1\n",
      "1    0           0      0         0         1         0\n",
      "2    0           0      0         0         1         0\n",
      "3    0           0      0         1         0         1\n",
      "4    0           0      0         0         0         1\n",
      "5    0           0      0         1         0         0\n",
      "6    0           0      0         0         0         0\n",
      "7    0           0      0         0         1         0\n",
      "8    0           0      0         0         1         0\n",
      "9    1           0      0         1         0         1\n"
     ]
    }
   ],
   "source": [
    "print(test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Sex',\n",
    "            'FamilySize',\n",
    "            'Child',\n",
    "            'Pclass.2',\n",
    "            'Pclass.3']\n",
    "target = 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entropy and information gain calculation function\n",
    "def getEntropy(data, feature, target):\n",
    "    tblSex = pd.crosstab(data[feature], data[target])\n",
    "    \n",
    "    if tblSex.shape[0] == 2:\n",
    "        mtrixArr = np.array(tblSex/tblSex.sum(axis = 1))\n",
    "        p1 = mtrixArr[0,0]\n",
    "        p2 = 1 - p1\n",
    "        p3 = mtrixArr[1,1]\n",
    "        p4 = 1- p3 \n",
    "        \n",
    "        mtrixArr2 = np.array(tblSex.sum(axis = 1)/len(train))\n",
    "        pf1 = mtrixArr2[0]\n",
    "        pf2 = mtrixArr2[1]\n",
    "        \n",
    "        # Entropy formula\n",
    "        if p1 == 0 or p2 == 0 or p3 == 0 or p4 == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            entropy = pf1*(-p1*math.log(p1) - p2*math.log(p2)) + pf2*(-p3*math.log(p3) - p4*math.log(p4))\n",
    "            return entropy\n",
    "    else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting best feature to split next, based on the entropy\n",
    "def best_splitting_feature(data, features, target):\n",
    "    best_feature = None\n",
    "    best_infoGain = 0;\n",
    "    entropy = 0\n",
    "    for feature in features:\n",
    "        # Calculate the information gain in the left split\n",
    "        entropy = getEntropy(data, feature, target)\n",
    "        infoGain = 1 - entropy\n",
    "        if infoGain == 1:\n",
    "            print (\"No more informaion gain\")\n",
    "            return None, 0\n",
    "            \n",
    "        if infoGain > best_infoGain:\n",
    "            best_infoGain = infoGain\n",
    "            best_feature = feature\n",
    "    print (\"Feature : [%s] Entropy: %s\" % (best_feature, round(entropy, 2)))\n",
    "    return best_feature, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ceating empty node function\n",
    "def create_leaf(target_values):    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True}  \n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == 0])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = +1    \n",
    "    else:\n",
    "        leaf['prediction'] = 0      \n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model building function\n",
    "def decision_tree_create(data, features, target, current_depth = 0, \n",
    "                         max_depth = 10, min_node_size=1, \n",
    "                         min_entropy=0.0):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    entropy = 0\n",
    "    target_values = data[target]\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    print(\"Depth = %s (%s data points)\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    # Stopping condition 2: No more features to split on.\n",
    "    if remaining_features == []:  \n",
    "        print(\"Stopping condition 2. \\n\\tNo remaining features.\")     \n",
    "        # If there are no remaining features to consider, make current node a leaf node\n",
    "        return create_leaf(target_values) \n",
    "    \n",
    "    # Early stopping condition 1: Reached max depth limit.\n",
    "    if current_depth >= max_depth:  \n",
    "        print(\"Early stopping condition 1. \\n\\tReached maximum depth.\")\n",
    "        # If the max tree depth has been reached, make current node a leaf node\n",
    "        return create_leaf(target_values)\n",
    "\n",
    "    # Early stopping condition 2: Data has less or equal to the minimum size.\n",
    "    if len(data) <= min_node_size:\n",
    "        print(\"Early stopping condition 2. \\n\\tReached minimum node size.\")\n",
    "        return create_leaf(target_values) \n",
    "    \n",
    "    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n",
    "    splitting_feature, entropy = best_splitting_feature(data, features, target)  \n",
    "    \n",
    "    # Stopping condition 1: All nodes are of the same type.\n",
    "    if splitting_feature == None:\n",
    "        print(\"Stopping condition 1. \\n\\tAll data points have the same target value.\")   \n",
    "        #  All data points in a node are from the same class.\n",
    "        return create_leaf(target_values)\n",
    "        \n",
    "    # Early stopping condition 3: Entropy value is less or equal to the minimum threshold.\n",
    "    if entropy <= min_entropy:\n",
    "        print(\"Early stopping condition 3. \\n\\tMinimum entropy.\")\n",
    "        return create_leaf(target_values)  \n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]   \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print(\"Split on feature [%s] (%s, %s)\" % (\\\n",
    "                    splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "        \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target])\n",
    "    if len(right_split) == len(data):\n",
    "        print(\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target])\n",
    "        \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, \n",
    "                                     current_depth + 1, max_depth, min_node_size, min_entropy)        \n",
    "    \n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, \n",
    "                                     current_depth + 1, max_depth, min_node_size, min_entropy)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counting node function\n",
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Traversing Tree function for the query \n",
    "def classify(tree, x):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        split_feature_value = np.array(split_feature_value)[0]\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            return classify(tree['right'], x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting output function\n",
    "def predict(model, data):\n",
    "    prediction = []\n",
    "    for i in range(0, len(data)):\n",
    "        pred = classify(model, data[i:i+1])\n",
    "        prediction.append(pred)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating accuracy function            \n",
    "def getAccuracy(prediction, data):\n",
    "    mask = (prediction == data[\"Survived\"])\n",
    "    return round(float(len(mask[mask == True])) / len(data), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "\tBuilding Tree Start\n",
      "--------------------------------------------------------------------\n",
      "Depth = 0 (712 data points)\n",
      "Feature : [Sex] Entropy: 0.62\n",
      "Split on feature [Sex] (463, 249)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 1 (463 data points)\n",
      "Feature : [Child] Entropy: 0.32\n",
      "Split on feature [Child] (417, 46)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 2 (417 data points)\n",
      "Feature : [Pclass.2] Entropy: 0.27\n",
      "Split on feature [Pclass.2] (339, 78)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (339 data points)\n",
      "Feature : [Pclass.3] Entropy: 0.22\n",
      "Split on feature [Pclass.3] (97, 242)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 4 (97 data points)\n",
      "Feature : [FamilySize] Entropy: 0.09\n",
      "Split on feature [FamilySize] (85, 12)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 5 (85 data points)\n",
      "Stopping condition 2. \n",
      "\tNo remaining features.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 5 (12 data points)\n",
      "Stopping condition 2. \n",
      "\tNo remaining features.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 4 (242 data points)\n",
      "Feature : [FamilySize] Entropy: 0.13\n",
      "Split on feature [FamilySize] (221, 21)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 5 (221 data points)\n",
      "Stopping condition 2. \n",
      "\tNo remaining features.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 5 (21 data points)\n",
      "Stopping condition 2. \n",
      "\tNo remaining features.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (78 data points)\n",
      "No more informaion gain\n",
      "Stopping condition 1. \n",
      "\tAll data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 2 (46 data points)\n",
      "Feature : [Pclass.3] Entropy: 0.03\n",
      "Split on feature [Pclass.3] (12, 34)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (12 data points)\n",
      "No more informaion gain\n",
      "Stopping condition 1. \n",
      "\tAll data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (34 data points)\n",
      "No more informaion gain\n",
      "Stopping condition 1. \n",
      "\tAll data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 1 (249 data points)\n",
      "Feature : [Pclass.3] Entropy: 0.16\n",
      "Split on feature [Pclass.3] (131, 118)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 2 (131 data points)\n",
      "Feature : [Pclass.2] Entropy: 0.04\n",
      "Split on feature [Pclass.2] (68, 63)\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (68 data points)\n",
      "Feature : [FamilySize] Entropy: 0.02\n",
      "Early stopping condition 3. \n",
      "\tMinimum entropy.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 3 (63 data points)\n",
      "No more informaion gain\n",
      "Stopping condition 1. \n",
      "\tAll data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Depth = 2 (118 data points)\n",
      "No more informaion gain\n",
      "Stopping condition 1. \n",
      "\tAll data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"\\tBuilding Tree Start\")\n",
    "model = decision_tree_create(train, features, 'Survived', max_depth = 5, \n",
    "                                min_node_size = 4, min_entropy=.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Total number of node : 19\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------------------------------------------------------------\")\n",
    "print(\"Total number of node : %s\" % count_nodes(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Prediction :', [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "prediction = predict(model, test)\n",
    "print(\"Prediction :\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy :', 0.8362)\n"
     ]
    }
   ],
   "source": [
    "accuracy = getAccuracy(prediction, test)\n",
    "print(\"Accuracy :\" , accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
