---
title: "Week4-5_Letter Recognition"
author: "Kyu Cho"
date: "July 1, 2015"
output: html_document
---
# Introduction
One of the earliest applications of the predictive analytics methods we have studied so far in this class was to automatically recognize letters, which post office machines use to sort mail. In this problem, we will build a model that uses statistics of images of four letters in the Roman alphabet -- A, B, P, and R -- to predict which letter a particular image corresponds to.  

Note that this is a multiclass classification problem. We have mostly focused on binary classification problems (e.g., predicting whether an individual voted or not, whether the Supreme Court will affirm or reverse a case, whether or not a person is at risk for a certain disease, etc.). In this problem, we have more than two classifications that are possible for each observation, like in the D2Hawkeye lecture.   

The file letters_ABPR.csv contains 3116 observations, each of which corresponds to a certain image of one of the four letters A, B, P and R. The images came from 20 different fonts, which were then randomly distorted to produce the final images; each such distorted image is represented as a collection of pixels, each of which is "on" or "off". For each such distorted image, we have available certain statistics of the image in terms of these pixels, as well as which of the four letters the image is. This data comes from the UCI Machine Learning Repository.  

# Variables
- letter = the letter that the image corresponds to (A, B, P or R)
- xbox = the horizontal position of where the smallest box covering the letter shape begins.
- ybox = the vertical position of where the smallest box covering the letter shape begins.
- width = the width of this smallest box.
- height = the height of this smallest box.
- onpix = the total number of "on" pixels in the character image
- xbar = the mean horizontal position of all of the "on" pixels
- ybar = the mean vertical position of all of the "on" pixels
- x2bar = the mean squared horizontal position of all of the "on" pixels in the image
- y2bar = the mean squared vertical position of all of the "on" pixels in the image
- xybar = the mean of the product of the horizontal and vertical position of all of the "on" pixels in the image
- x2ybar = the mean of the product of the squared horizontal position and the vertical position of all of the "on" pixels
- xy2bar = the mean of the product of the horizontal position and the squared vertical position of all of the "on" pixels
- xedge = the mean number of edges (the number of times an "off" pixel is followed by an "on" pixel, or the image boundary is hit) as the image is scanned from left to right, along the whole vertical length of the image
- xedgeycor = the mean of the product of the number of horizontal edges at each vertical position and the vertical position
- yedge = the mean number of edges as the images is scanned from top to bottom, along the whole horizontal length of the image
- yedgexcor = the mean of the product of the number of vertical edges at each horizontal position and the horizontal position

```{r cache=TRUE, hide=TRUE}
library(caTools)
library(plyr)
library(gplots)
library(ggplot2)

# To plot the tree
library(rpart)
library(rpart.plot)

# For building randomForest model
library(randomForest)

# For validating the model
library(ROCR)

# For crossvalidation
library(caret)
library(e1071)
setwd("D:/Google Drive/College/4-The Analytics Edge/data4")
letters = read.csv("letters_ABPR.csv")
summary(letters)
str(letters)
```

# PREDICTING B OR NOT B
## Base line Model
```{r cache=TRUE}
letters$isB = as.factor(letters$letter == "B")

set.seed(1000)
split = sample.split(letters$isB, SplitRatio = 0.5)
train = subset(letters, split == TRUE)
test = subset(letters, split == FALSE)

# let's consider a baseline method that always predicts the most frequent outcome, which is "not B".
# What's the accuracy of the baseline model on the test set?
table = table(test$isB)
accuracy = table[1]/sum(table)
accuracy
```

## CART Model
Now build a classification tree to predict whether a letter is a B or not, using the training set to build your model. Remember to remove the variable "letter" out of the model, as this is related to what we are trying to predict.  
We are just using the default parameters in our CART model, so we don't need to add the minbucket or cp arguments at all. We also added the argument method="class" since this is a classification problem.
```{r cache=TRUE}
# What is the accuracy of the CART model on the test set?
CARTb = rpart(isB ~ . - letter, data=train, method="class")
pred = predict(CARTb, newdata=test, type="class")
table2 = table(test$isB, pred)
accuracy2 = (table2[1,1]+table2[2,2])/sum(table2)
accuracy
```

## Randome Forest Model
Now, build a random forest model to predict whether the letter is a B or not (the isB variable) using the training set. You should use all of the other variables as independent variables, except letter (since it helped us define what we are trying to predict!). 
```{r cache=TRUE}
# What's the accuracy of the random forest model on the testing data?
set.seed(1000)
RDF = randomForest(isB ~ . -letter, data=train)
pred2 = predict(RDF, newdata=test, type="class")
table3 = table(test$isB, pred2)
accuracy3 = (table3[1,1]+table3[2,2])/sum(table3)
accuracy3
```
The random forests tends to improve on CART in terms of predictive accuracy. Sometimes, this improvement can be quite significant, as it is here.

# PREDICTING THE LETTERS A, B, P, R
The variable in our data frame which we will be trying to predict is "letter". Start by converting letter in the original data set (letters) to a factor by running the following command in R:
```{r cache=TRUE}
# Convert into factor
letters$letter = as.factor( letters$letter )
```
In a multiclass classification problem, a simple baseline model is to predict the most frequent class of all of the options.

```{r cache=TRUE}
# What's the accuracy of the baseline model?
set.seed(2000)
split2 = sample.split(letters$letter, SplitRatio=0.5)
train2 = subset(letters, split2==TRUE)
test2 = subset(letters, split2==FALSE)
Accuracy4 = max(table(test2$letter))/sum(table(test2$letter))
Accuracy4

# What's the accuracy of the CART model for multi letters?
CARTmulti = rpart(letter ~. -isB, data=train2, method="class")
pred3 = predict(CARTmulti, newdata=test2, type="class")
table4 = table(test2$letter, pred3)
Accuracy5 = (table4[1,1]+table4[2,2]+table4[3,3]+table4[4,4])/sum(table4)
Accuracy5

# What's the accuracy of the random forest model on the training data?
set.seed(1000)
RDF2 = randomForest(letter ~. -isB, data=train2, mehod="class")
pred4 = predict(RDF2, newdata=test2, type="class")
table5 = table(test2$letter, pred4)
Accuracy5 = (table5[1,1]+table5[2,2]+table5[3,3]+table5[4,4])/sum(table5)
Accuracy5
```
You should find this value rather striking, for several reasons. The first is that it is significantly higher than the value for CART, highlighting the gain in accuracy that is possible from using random forest models. The second is that while the accuracy of CART decreased significantly as we transitioned from the problem of predicting B/not B (a relatively simple problem) to the problem of predicting the four letters (certainly a harder problem), the accuracy of the random forest model decreased by a tiny amount.  























