---
title: "Week4-4_Why people vote"
author: "Kyu Cho"
date: "July 1, 2015"
output: html_document
---
# Introduction
In August 2006 three researchers (Alan Gerber and Donald Green of Yale University, and Christopher Larimer of the University of Northern Iowa) carried out a large scale field experiment in Michigan, USA to test the hypothesis that one of the reasons people vote is social, or extrinsic, pressure. To quote the first paragraph of their 2008 research paper:  

Among the most striking features of a democratic political system is the participation of millions of voters in elections. Why do large numbers of people vote, despite the fact that ... "the casting of a single vote is of no significance where there is a multitude of electors"? One hypothesis is adherence to social norms. Voting is widely regarded as a citizen duty, and citizens worry that others will think less of them if they fail to participate in elections. Voters' sense of civic duty has long been a leading explanation of vote turnout...  

# Variables
The researchers grouped about 344,000 voters into different groups randomly - about 191,000 voters were a "control" group, and the rest were categorized into one of four "treatment" groups. These five groups correspond to five binary variables in the dataset.

- "Civic Duty" (variable civicduty) group members were sent a letter that simply said "DO YOUR CIVIC DUTY - VOTE!"
"Hawthorne Effect" (variable hawthorne) group members were sent a letter that had the "Civic Duty" message plus the additional message "YOU ARE BEING STUDIED" and they were informed that their voting behavior would be examined by means of public records.
- "Self" (variable self) group members received the "Civic Duty" message as well as the recent voting record of everyone in that household and a message stating that another message would be sent after the election with updated records.
- "Neighbors" (variable neighbors) group members were given the same message as that for the "Self" group, except the message not only had the household voting records but also that of neighbors - maximizing social pressure.
- "Control" (variable control) group members were not sent anything, and represented the typical voting situation.
Additional variables include sex (0 for male, 1 for female), yob (year of birth), and the dependent variable voting (1 if they voted, 0 otherwise).

```{r cache=TRUE, hide=TRUE}
library(caTools)
library(plyr)
library(gplots)
library(ggplot2)

# To plot the tree
library(rpart)
library(rpart.plot)

# For building randomForest model
library(randomForest)

# For validating the model
library(ROCR)

# For crossvalidation
library(caret)
library(e1071)

setwd("D:/Google Drive/College/4-The Analytics Edge/data4")
gerber = read.csv("gerber.csv")
summary(gerber)
str(gerber)
```

```{r cache=TRUE}
# Which of the four "treatment groups" had the largest percentage of people who actually voted (voting = 1)?
tapply(gerber$voting, gerber$civicduty, mean)
tapply(gerber$voting, gerber$hawthorne, mean)
tapply(gerber$voting, gerber$self, mean)
tapply(gerber$voting, gerber$neighbors, mean)
```

# EXPLORATION AND LOGISTIC REGRESSION  
```{r cache=TRUE}
# Build model
mod1 = glm(voting~civicduty+hawthorne+self+neighbors, data=gerber, family="binomial")
summary(mod1)

#Using a threshold of 0.3 and 0.5, what is the accuracy of the logistic regression model? (no need to use the newdata argument since we didn't split our data.)
pred = predict(mod1, type="response")

# Find the perfect threshold
library(ROCR)
ROCRpred = prediction(pred, gerber$voting)
ROCRperf = performance(ROCRpred, "tpr", "fpr")

# increment the point by 0.1
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))

table(gerber$voting, pred > 0.3)
(134513+51966)/(134513+51966+56730+100875)

table(gerber$voting, pred > 0.5)
235388/(235388+108696)

# compute the AUC
ROCRpred = prediction(pred, gerber$voting)
as.numeric(performance(ROCRpred, "auc")@y.values)
```
Even though all of our variables are significant, our model does not improve over the baseline model of just predicting that someone will not vote, and the AUC is low. So while the treatment groups do make a difference, this is a weak predictive model.  

# TREE
Let's try tree without *method="class"*  
We are actually going to create a regression tree here. We are interested in building a tree to explore the fraction of people who vote, or the probability of voting. We'd like CART to split our groups if they have different probabilities of voting.  
If we used method='class', CART would only split if one of the groups had a probability of voting above 50% and the other had a probability of voting less than 50% (since the predicted outcomes would be different). However, with regression trees, CART will split even if both groups have probability less than 50%.  

```{r cache=TRUE}
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
prp(CARTmodel)
```
There are no splits in the tree, because none of the variables make a big enough effect to be split on.  

```{r cache=TRUE}
CARTmodel2 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(CARTmodel2)
```
The fraction of 0.31 of "Civic Duty" people voted.  

```{r cache=TRUE}
CARTmodel3 = rpart(voting ~ civicduty + hawthorne + self + neighbors + sex, data=gerber, cp=0.0)
prp(CARTmodel3)
```
We see that male tends to vote more than female.  

# INTERACTION TERMS  
```{r cache=TRUE}
CARTmodel4 = rpart(voting ~ control, data=gerber, cp=0.0)
CARTmodel5 = rpart(voting ~ control + sex, data=gerber, cp=0.0)

# In the "control" only tree, what is the absolute value of the difference in the predicted probability of voting between being in the control group versus being in a different group?
prp(CARTmodel4, digits=6)

# Going back to logistic regression now, create a model using "sex" and "control". Interpret the coefficient for "sex"
fitLog <- glm(voting ~ control + sex, data=gerber, family='binomial')
summary(fitLog)
```
If you look at the summary of the model, you can see that the coefficient for the "sex" variable is -0.055791. This means that women are less likely to vote, since women have a larger value in the sex variable, and a negative coefficient means that larger values are predictive of 0.  

The regression tree calculated the percentage voting exactly for every one of the four possibilities (Man, Not Control), (Man, Control), (Woman, Not Control), (Woman, Control). Logistic regression has attempted to do the same, although it wasn't able to do as well because it can't consider exactly the joint possibility of being a women and in the control group.
```{r cache=TRUE}
Possibilities <- data.frame(sex = c(0,0,1,1), control = c(0,1,0,1))
# predict(CARTmodel5, newdata = Possibilities, type = "response")

#So the difference is not too big for this dataset, but it is there. We're going to add a new term to our logistic regression now, that is the combination of the "sex" and "control" variables - so if this new variable is 1, that means the person is a woman AND in the control group.
LogModel2 = glm(voting ~ sex + control + sex:control, data=gerber, family="binomial")
summary(LogModel2)
```
This coefficient is negative, so that means that a value of 1 in this variable decreases the chance of voting. This variable will have variable 1 if the person is a woman and in the control group.

```{r cache=TRUE}
# Now what is the difference between the logistic regression model and the CART model for the (Woman, Control) case? Again, give your answer with five numbers after the decimal point.

```
logistic regression is 0.2904558, tree is 0.290456
```{r cache=TRUE}
predict(LogModel2, newdata=Possibilities, type="response")
```

We should not use all possible interaction terms in a logistic regression model due to overfitting. Even in this simple problem, we have four treatment groups and two values for sex. If we have an interaction term for every treatment variable with sex, we will double the number of variables. In smaller data sets, this could quickly lead to overfitting.